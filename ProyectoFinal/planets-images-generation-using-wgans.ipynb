{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6099900,"sourceType":"datasetVersion","datasetId":3493936}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Planets Images Generation using a Wasserstein Deep Convolutional Generative Adversarial Networks\n\n#### Final Project: Tópicos Avanzados en Estadística 1\n#### Universidad Nacional de Colombia\n\n__Integrantes:__ Andres Acevedo & Angel Martínez","metadata":{}},{"cell_type":"code","source":"# Importing the libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport os\nimport PIL\nimport time\nimport glob\nimport imageio\nfrom IPython import display\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import SGD, Adam\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Input, Dense, LeakyReLU, Dropout, BatchNormalization, Reshape, Conv2DTranspose, Conv2D, Flatten","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-15T19:27:44.547957Z","iopub.execute_input":"2023-11-15T19:27:44.548336Z","iopub.status.idle":"2023-11-15T19:28:03.824472Z","shell.execute_reply.started":"2023-11-15T19:27:44.548305Z","shell.execute_reply":"2023-11-15T19:28:03.823629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n## Loading the Dataset","metadata":{}},{"cell_type":"code","source":"# Data augmentation for the training dataset images\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                   #rotation_range=40,\n                                   #width_shift_range=0.2,\n                                   #height_shift_range=0.2,\n                                   #shear_range=0.2,\n                                   #zoom_range=0.2,\n                                   horizontal_flip=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T19:28:03.826719Z","iopub.execute_input":"2023-11-15T19:28:03.827288Z","iopub.status.idle":"2023-11-15T19:28:03.833015Z","shell.execute_reply.started":"2023-11-15T19:28:03.827261Z","shell.execute_reply":"2023-11-15T19:28:03.832022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading the planets images dataset (augmented)\nBATCH_SIZE = 256\nIMAGE_SIZE = 80\n\nimage_generator = train_datagen.flow_from_directory('/kaggle/input/solar-system-planets/planetsdataset_completo/training',\n                                 target_size=(IMAGE_SIZE, IMAGE_SIZE),\n                                 batch_size=BATCH_SIZE,\n                                 class_mode='sparse')\n                                 #color_mode='grayscale')","metadata":{"execution":{"iopub.status.busy":"2023-11-15T19:28:03.834204Z","iopub.execute_input":"2023-11-15T19:28:03.834462Z","iopub.status.idle":"2023-11-15T19:28:04.030807Z","shell.execute_reply.started":"2023-11-15T19:28:03.834439Z","shell.execute_reply":"2023-11-15T19:28:04.030087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_generator.class_indices","metadata":{"execution":{"iopub.status.busy":"2023-11-15T19:28:04.031962Z","iopub.execute_input":"2023-11-15T19:28:04.032380Z","iopub.status.idle":"2023-11-15T19:28:04.040531Z","shell.execute_reply.started":"2023-11-15T19:28:04.032342Z","shell.execute_reply":"2023-11-15T19:28:04.039622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in image_generator:\n    print(batch[1].shape)\n    print(sum([batch[0][batch[1] == i].shape[0] for i in [0., 1., 2., 3., 4., 5., 6., 7., 8.]]))\n    break","metadata":{"execution":{"iopub.status.busy":"2023-11-15T19:28:04.043743Z","iopub.execute_input":"2023-11-15T19:28:04.044451Z","iopub.status.idle":"2023-11-15T19:28:06.035611Z","shell.execute_reply.started":"2023-11-15T19:28:04.044419Z","shell.execute_reply":"2023-11-15T19:28:06.034578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load all the generated images in NumPy tensors (filtering the desired class)\nclass_index_to_select = 0.\nselected_images = []\n\nfor batch in image_generator:\n    batch_labels = batch[1]  # Obtaining the labels (index 1)\n    mask = (batch_labels == class_index_to_select)\n    selected_batch = batch[0][mask]  # Filtering the images by label\n    selected_images.append(selected_batch)\n    print(selected_batch[0].shape)\n    \n    if len(selected_images) * BATCH_SIZE >= len(image_generator.filenames):\n        break\n\nimages = tf.concat(selected_images, axis=0)  # Concat every batch\n\n# Numpy tensor shape\nprint(\"Tensores de imágenes:\", images.shape)\n\n# Creating a Dataset from the Numpy tensor\nBUFFER_SIZE = 1834  # Computer RAM size for temporaly storage\nBATCH_SIZE = 256\n\n# Batch and shuffle the data\ndataset = tf.data.Dataset.from_tensor_slices(images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T19:28:06.037229Z","iopub.execute_input":"2023-11-15T19:28:06.038135Z","iopub.status.idle":"2023-11-15T19:28:23.580831Z","shell.execute_reply.started":"2023-11-15T19:28:06.038104Z","shell.execute_reply":"2023-11-15T19:28:23.579880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(25):\n  plt.subplot(5, 5, i+1)\n  plt.axis(\"off\")\n  #plt.imshow(images[i], cmap='gray')\n  plt.imshow(images[i])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T19:28:23.582232Z","iopub.execute_input":"2023-11-15T19:28:23.582973Z","iopub.status.idle":"2023-11-15T19:28:24.624078Z","shell.execute_reply.started":"2023-11-15T19:28:23.582936Z","shell.execute_reply":"2023-11-15T19:28:24.623085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n## Defining the model","metadata":{}},{"cell_type":"code","source":"# Defining the generator\n\nLATENT_DIM = 100\n\ndef make_generator_model(latent_dim = LATENT_DIM):\n  i = Input(shape=(latent_dim, ))  # (latent_dim, ) -> (100, )\n\n  x = Dense(IMAGE_SIZE//4 * IMAGE_SIZE//4 * 256, use_bias=False)(i)  # (20 * 20 * 256, )\n  x = BatchNormalization()(x)\n  x = LeakyReLU()(x)\n\n  x = Reshape((IMAGE_SIZE//4, IMAGE_SIZE//4, 256))(x)  # (20, 20, 256)\n    \n  x = Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)(x)  # (20, 20, 128)\n  x = BatchNormalization()(x)\n  x = LeakyReLU()(x)\n\n  x = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)  # (40, 40, 64)\n  x = BatchNormalization()(x)\n  x = LeakyReLU()(x)\n\n  x = Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='sigmoid')(x)  # (80, 80, 3) -> generated image\n\n  model = Model(i, x)\n  return model","metadata":{"execution":{"iopub.status.busy":"2023-11-15T19:28:24.625519Z","iopub.execute_input":"2023-11-15T19:28:24.625869Z","iopub.status.idle":"2023-11-15T19:28:24.636532Z","shell.execute_reply.started":"2023-11-15T19:28:24.625836Z","shell.execute_reply":"2023-11-15T19:28:24.635632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = make_generator_model()\n\n# Generator Network Architecture\ngenerator.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T19:28:24.637903Z","iopub.execute_input":"2023-11-15T19:28:24.638303Z","iopub.status.idle":"2023-11-15T19:28:24.870346Z","shell.execute_reply.started":"2023-11-15T19:28:24.638267Z","shell.execute_reply":"2023-11-15T19:28:24.869404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the generator (still untrained) to create an image\nnoise = tf.random.normal([1, 100])\ngenerated_image = generator(noise, training=False)\n\nprint(generated_image.shape)\n#plt.imshow(generated_image[0], cmap='gray')\nplt.imshow(generated_image[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-15T19:28:24.877651Z","iopub.execute_input":"2023-11-15T19:28:24.878008Z","iopub.status.idle":"2023-11-15T19:28:36.521907Z","shell.execute_reply.started":"2023-11-15T19:28:24.877977Z","shell.execute_reply":"2023-11-15T19:28:36.520965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining the discriminator\n\ndef make_discriminator_model():\n  i = Input(shape=[IMAGE_SIZE, IMAGE_SIZE, 3])  # (80, 80, 3)\n\n  x = Conv2D(64, (5, 5), strides=(2, 2), padding='same', activation='leaky_relu')(i)  # (40, 40, 64)\n  x = Dropout(0.3)(x)\n        \n  x = Conv2D(128, (5, 5), strides=(2, 2), padding='same', activation='leaky_relu')(x)  # (20, 20, 128)\n  x = Dropout(0.3)(x)\n\n  x = Flatten()(x)  # (20 * 20 * 128, )\n  x = Dense(1)(x)  # (1, ) -> real or fake\n\n  model = Model(i, x)\n  return model","metadata":{"execution":{"iopub.status.busy":"2023-11-15T19:28:36.523439Z","iopub.execute_input":"2023-11-15T19:28:36.524172Z","iopub.status.idle":"2023-11-15T19:28:36.531615Z","shell.execute_reply.started":"2023-11-15T19:28:36.524133Z","shell.execute_reply":"2023-11-15T19:28:36.530546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = make_discriminator_model()\n\n# Discriminator Network Architecture\ndiscriminator.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T19:28:36.532938Z","iopub.execute_input":"2023-11-15T19:28:36.533470Z","iopub.status.idle":"2023-11-15T19:28:36.625916Z","shell.execute_reply.started":"2023-11-15T19:28:36.533435Z","shell.execute_reply":"2023-11-15T19:28:36.624960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the discriminator (still untrained) to classify the generated images as real or fake\ndecision = discriminator(generated_image)\nprint(decision)  # Note that the discriminator is sure it is fake (0% prob. to be real)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T19:28:36.627159Z","iopub.execute_input":"2023-11-15T19:28:36.627512Z","iopub.status.idle":"2023-11-15T19:28:36.992896Z","shell.execute_reply.started":"2023-11-15T19:28:36.627479Z","shell.execute_reply":"2023-11-15T19:28:36.991941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Suggested hyperparameters in the research paper's algorithm\n\ngenerator_optimizer = tf.keras.optimizers.Adam(\n\tlearning_rate=0.0002, beta_1=0.5, beta_2=0.9)\n\ndiscriminator_optimizer = tf.keras.optimizers.Adam(\n    learning_rate=0.0002, beta_1=0.5, beta_2=0.9)\n\ndef discriminator_loss(real_img, fake_img):\n    real_loss = tf.reduce_mean(real_img)\n    fake_loss = tf.reduce_mean(fake_img)\n    return - fake_loss + real_loss\n\ndef generator_loss(fake_img):\n    return tf.reduce_mean(fake_img)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T19:28:36.996781Z","iopub.execute_input":"2023-11-15T19:28:36.997080Z","iopub.status.idle":"2023-11-15T19:28:37.008064Z","shell.execute_reply.started":"2023-11-15T19:28:36.997053Z","shell.execute_reply":"2023-11-15T19:28:37.007066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This method returns a helper function to compute cross entropy loss\ncross_entropy = BinaryCrossentropy(from_logits=True)\n\n# Discriminator loss\ndef discriminator_loss(real_output, fake_output):\n  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n  total_loss = real_loss + fake_loss\n  return total_loss\n\n# Generator loss\ndef generator_loss(fake_output):\n  return cross_entropy(tf.ones_like(fake_output), fake_output)\n\n# Optimizers\ngenerator_optimizer = Adam(1e-4)\ndiscriminator_optimizer = Adam(1e-4)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T19:28:37.009285Z","iopub.execute_input":"2023-11-15T19:28:37.009634Z","iopub.status.idle":"2023-11-15T19:28:37.021361Z","shell.execute_reply.started":"2023-11-15T19:28:37.009602Z","shell.execute_reply":"2023-11-15T19:28:37.020503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving checkpoints\ncheckpoint_dir = './training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T19:28:37.022561Z","iopub.execute_input":"2023-11-15T19:28:37.023404Z","iopub.status.idle":"2023-11-15T19:28:37.034830Z","shell.execute_reply.started":"2023-11-15T19:28:37.023354Z","shell.execute_reply":"2023-11-15T19:28:37.033906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining the training cycle\n\nEPOCHS = 10000\nnoise_dim = 100\nnum_examples_to_generate = 16\n\n# You will reuse this seed overtime (so it's easier) to visualize progress in the animated GIF)\nseed = tf.random.normal([num_examples_to_generate, noise_dim])\n\n# Notice the use of `tf.function`\n# This annotation causes the function to be \"compiled\"\n@tf.function\ndef train_step(images):\n  noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:  # This computes the generator and discriminator gradients\n\n    generated_images = generator(noise, training=True)\n\n    real_output = discriminator(images, training=True)\n    fake_output = discriminator(generated_images, training=True)\n\n    gen_loss = generator_loss(fake_output)\n    disc_loss = discriminator_loss(real_output, fake_output)\n\n  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)  # Generator gradients\n  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)  # Discriminator gradients\n\n  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))  # Optimizing generator params\n  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))  # Optimizing discriminator params","metadata":{"execution":{"iopub.status.busy":"2023-11-15T19:28:37.036218Z","iopub.execute_input":"2023-11-15T19:28:37.036479Z","iopub.status.idle":"2023-11-15T19:28:37.047676Z","shell.execute_reply.started":"2023-11-15T19:28:37.036457Z","shell.execute_reply":"2023-11-15T19:28:37.046984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generating and saving images for a given epoch\n\ndef generate_and_save_images(model, epoch, test_input):\n  # Notice `training` is set to False\n  # This is so all layers run in inference mode (batchnorm)\n  predictions = model(test_input, training=False)  # Generated image from a given seed in a trained model\n\n  fig = plt.figure(figsize=(4, 4))\n\n  for i in range(predictions.shape[0]):\n      plt.subplot(4, 4, i+1)\n      #plt.imshow(predictions[i], cmap='gray')\n      plt.imshow(predictions[i])\n      plt.axis('off')\n\n  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T19:28:37.048860Z","iopub.execute_input":"2023-11-15T19:28:37.049464Z","iopub.status.idle":"2023-11-15T19:28:37.063661Z","shell.execute_reply.started":"2023-11-15T19:28:37.049438Z","shell.execute_reply":"2023-11-15T19:28:37.062838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"######################\n### TRAINING CYCLE ###\n######################\n\ndef train(dataset, epochs):\n  for epoch in range(epochs):\n    start = time.time()  # Starting time\n\n    for image_batch in dataset:\n      train_step(image_batch)\n\n    # Save the model every 100 epochs\n    if (epoch + 1) % 100 == 0:\n      checkpoint.save(file_prefix = checkpoint_prefix)\n      # Produce images for the GIF as you go\n      display.clear_output(wait=True)  # It doesn't shows the NN training outputs\n      generate_and_save_images(generator,\n                               epoch + 1,\n                               seed)\n\n    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))  # It only shows the time spent in each epoch\n\n  # Generate after the final epoch\n  display.clear_output(wait=True)\n  generate_and_save_images(generator,\n                           epochs,\n                           seed)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T19:28:37.065221Z","iopub.execute_input":"2023-11-15T19:28:37.065568Z","iopub.status.idle":"2023-11-15T19:28:37.075846Z","shell.execute_reply.started":"2023-11-15T19:28:37.065530Z","shell.execute_reply":"2023-11-15T19:28:37.075100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the Model (generator and discriminator simultaneously)\ntrain(dataset, EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T19:28:37.077006Z","iopub.execute_input":"2023-11-15T19:28:37.077380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Restoring the last checkpoint\ncheckpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display a single image using the epoch number\ndef display_image(epoch_no):\n  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\n\ndisplay_image(EPOCHS)  # Last image generated (at the final epoch)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a GIF using imageio with the images saved during the training\nanim_file = 'dcgan.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n  filenames = glob.glob('image*.png')\n  filenames = sorted(filenames)\n  for filename in filenames:\n    image = imageio.imread(filename)\n    writer.append_data(image)\n  image = imageio.imread(filename)\n  writer.append_data(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install tensorflow_docs  # This is required to shows the aminated GIF","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_docs.vis.embed as embed\nembed.embed_file(anim_file)  # This shows the aminated GIF","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The END!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}