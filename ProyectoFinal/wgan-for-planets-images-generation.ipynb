{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6099900,"sourceType":"datasetVersion","datasetId":3493936}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Planets Images Generation using a Wasserstein Deep Convolutional Generative Adversarial Networks\n\n#### Final Project: Tópicos Avanzados en Estadística 1\n#### Universidad Nacional de Colombia\n\n__Integrantes:__ Andres Acevedo & Angel Martínez","metadata":{}},{"cell_type":"code","source":"# Importing the essential libraries\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-15T07:06:16.104592Z","iopub.execute_input":"2023-11-15T07:06:16.105112Z","iopub.status.idle":"2023-11-15T07:06:28.898161Z","shell.execute_reply.started":"2023-11-15T07:06:16.105077Z","shell.execute_reply":"2023-11-15T07:06:28.897262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n## Loading the dataset","metadata":{}},{"cell_type":"code","source":"# Data augmentation for the training dataset images\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                   #rotation_range=40,\n                                   #width_shift_range=0.2,\n                                   #height_shift_range=0.2,\n                                   #shear_range=0.2,\n                                   #zoom_range=0.2,\n                                   horizontal_flip=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:12:23.649273Z","iopub.execute_input":"2023-11-15T07:12:23.649990Z","iopub.status.idle":"2023-11-15T07:12:23.654536Z","shell.execute_reply.started":"2023-11-15T07:12:23.649937Z","shell.execute_reply":"2023-11-15T07:12:23.653652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading the planets images dataset (augmented)\nBATCH_SIZE = 256\nIMAGE_SIZE = 80\n\nimage_generator = train_datagen.flow_from_directory('/kaggle/input/solar-system-planets/planetsdataset_completo/training',\n                                 target_size=(IMAGE_SIZE, IMAGE_SIZE),\n                                 batch_size=BATCH_SIZE,\n                                 class_mode='sparse')\n                                 #color_mode='grayscale')","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:12:24.350268Z","iopub.execute_input":"2023-11-15T07:12:24.351004Z","iopub.status.idle":"2023-11-15T07:12:24.434743Z","shell.execute_reply.started":"2023-11-15T07:12:24.350940Z","shell.execute_reply":"2023-11-15T07:12:24.434020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_generator.class_indices","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:12:28.267475Z","iopub.execute_input":"2023-11-15T07:12:28.268156Z","iopub.status.idle":"2023-11-15T07:12:28.274356Z","shell.execute_reply.started":"2023-11-15T07:12:28.268122Z","shell.execute_reply":"2023-11-15T07:12:28.273331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in image_generator:\n    print(batch[1].shape)\n    print(sum([batch[0][batch[1] == i].shape[0] for i in [0., 1., 2., 3., 4., 5., 6., 7., 8.]]))\n    break","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:12:31.073972Z","iopub.execute_input":"2023-11-15T07:12:31.074940Z","iopub.status.idle":"2023-11-15T07:12:31.607325Z","shell.execute_reply.started":"2023-11-15T07:12:31.074906Z","shell.execute_reply":"2023-11-15T07:12:31.606333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load all the generated images in NumPy tensors (filtering the desired class)\nclass_index_to_select = 0.\nselected_images = []\n\nfor batch in image_generator:\n    batch_labels = batch[1]  # Obtaining the labels (index 1)\n    mask = (batch_labels == class_index_to_select)\n    selected_batch = batch[0][mask]  # Filtering the images by label\n    selected_images.append(selected_batch)\n    print(selected_batch[0].shape)\n    \n    if len(selected_images) * BATCH_SIZE >= len(image_generator.filenames):\n        break\n\nimages = tf.concat(selected_images, axis=0)  # Concat every batch\n\n# Numpy tensor shape\nprint(\"Tensores de imágenes:\", images.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:12:32.776615Z","iopub.execute_input":"2023-11-15T07:12:32.776964Z","iopub.status.idle":"2023-11-15T07:12:37.420568Z","shell.execute_reply.started":"2023-11-15T07:12:32.776938Z","shell.execute_reply":"2023-11-15T07:12:37.419599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(25):\n  plt.subplot(5, 5, i+1)\n  plt.axis(\"off\")\n  #plt.imshow(images[i], cmap='gray')\n  plt.imshow(images[i])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:12:38.897428Z","iopub.execute_input":"2023-11-15T07:12:38.897793Z","iopub.status.idle":"2023-11-15T07:12:39.708857Z","shell.execute_reply.started":"2023-11-15T07:12:38.897763Z","shell.execute_reply":"2023-11-15T07:12:39.707839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n## Defining the model","metadata":{}},{"cell_type":"code","source":"# Defining parameters\n\nIMG_SHAPE = (80, 80, 3)  # RGB\nBATCH_SIZE = 512\nnoise_dim = 128  # latent dim","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:07:17.914256Z","iopub.execute_input":"2023-11-15T07:07:17.914613Z","iopub.status.idle":"2023-11-15T07:07:17.919369Z","shell.execute_reply.started":"2023-11-15T07:07:17.914585Z","shell.execute_reply":"2023-11-15T07:07:17.918353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv_block(x, filters, activation, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n               use_bias=True, use_bn=False, use_dropout=False, drop_value=0.5):\n\n    x = layers.Conv2D(filters, kernel_size, strides=strides,\n                      padding=padding, use_bias=use_bias)(x)\n\n    if use_bn:\n        x = layers.BatchNormalization()(x)\n    x = activation(x)\n    if use_dropout:\n        x = layers.Dropout(drop_value)(x)\n\n    return x","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:06:58.362242Z","iopub.execute_input":"2023-11-15T07:06:58.363157Z","iopub.status.idle":"2023-11-15T07:06:58.369568Z","shell.execute_reply.started":"2023-11-15T07:06:58.363123Z","shell.execute_reply":"2023-11-15T07:06:58.368488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def upsample_block(x, filters, activation, kernel_size=(3, 3), strides=(1, 1), up_size=(2, 2), padding=\"same\",\n                   use_bn=False, use_bias=True, use_dropout=False, drop_value=0.3):\n\n    x = layers.UpSampling2D(up_size)(x)\n    x = layers.Conv2D(filters, kernel_size, strides=strides,\n                      padding=padding, use_bias=use_bias)(x)\n\n    if use_bn:\n        x = layers.BatchNormalization()(x)\n\n    if activation:\n        x = activation(x)\n    if use_dropout:\n        x = layers.Dropout(drop_value)(x)\n\n    return x","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:07:02.380538Z","iopub.execute_input":"2023-11-15T07:07:02.380890Z","iopub.status.idle":"2023-11-15T07:07:02.387819Z","shell.execute_reply.started":"2023-11-15T07:07:02.380856Z","shell.execute_reply":"2023-11-15T07:07:02.386836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Constructing the Generator architecture\n\ndef get_generator_model():\n    noise = layers.Input(shape=(noise_dim,))  # (128, )\n    x = layers.Dense(10 * 10 * 256, use_bias=False)(noise)  # (10 * 10 * 256, )\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU(0.2)(x)\n\n    x = layers.Reshape((10, 10, 256))(x)  # (10, 10, 256)\n\n    x = upsample_block(x, 128, layers.LeakyReLU(0.2), strides=(1, 1), use_bias=False,\n                       use_bn=True, padding=\"same\", use_dropout=False)  # (20, 20, 128)\n\n    x = upsample_block(x, 64, layers.LeakyReLU(0.2), strides=(1, 1), use_bias=False,\n                       use_bn=True, padding=\"same\", use_dropout=False)  # (40, 40, 64)\n\n    x = upsample_block(x, 3, layers.Activation(\"sigmoid\"), strides=(1, 1),\n                       use_bias=False, use_bn=True)  # (80, 80, 3)\n\n    g_model = keras.models.Model(noise, x, name=\"generator\")\n    return g_model\n\n\ng_model = get_generator_model()\ng_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:07:20.579226Z","iopub.execute_input":"2023-11-15T07:07:20.580070Z","iopub.status.idle":"2023-11-15T07:07:20.821294Z","shell.execute_reply.started":"2023-11-15T07:07:20.580038Z","shell.execute_reply":"2023-11-15T07:07:20.820402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Constructing the Discriminator (Critic) architecture\n\ndef get_discriminator_model():\n\n    img_input = layers.Input(shape=IMG_SHAPE)  # (80, 80, 3)\n\n    x = conv_block(img_input, 64, kernel_size=(5, 5), strides=(2, 2), use_bn=False, use_bias=True,\n                   activation=layers.LeakyReLU(0.2), use_dropout=False, drop_value=0.3)\n    # (40, 40, 64)\n\n    x = conv_block(x, 128, kernel_size=(5, 5), strides=(2, 2), use_bn=False, use_bias=True,\n                   activation=layers.LeakyReLU(0.2), use_dropout=True, drop_value=0.3)\n    # (20, 20, 128)\n\n    x = conv_block(x, 256, kernel_size=(5, 5), strides=(2, 2), use_bn=False, use_bias=True,\n                   activation=layers.LeakyReLU(0.2), use_dropout=True, drop_value=0.3)\n    # (10, 10, 256)\n\n    x = conv_block(x, 512, kernel_size=(5, 5), strides=(2, 2), use_bn=False, use_bias=True,\n                   activation=layers.LeakyReLU(0.2), use_dropout=False, drop_value=0.3)\n    # (5, 5, 512)\n\n    x = layers.Flatten()(x)  # (5 * 5 * 512, )\n    x = layers.Dropout(0.2)(x)\n    x = layers.Dense(1)(x)\n\n    d_model = keras.models.Model(img_input, x, name=\"discriminator\")\n    return d_model\n\n\nd_model = get_discriminator_model()\nd_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:10:00.447211Z","iopub.execute_input":"2023-11-15T07:10:00.447562Z","iopub.status.idle":"2023-11-15T07:10:00.586471Z","shell.execute_reply.started":"2023-11-15T07:10:00.447533Z","shell.execute_reply":"2023-11-15T07:10:00.585438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the overall WGAN model\n\nclass WGAN(keras.Model):\n    def __init__(self, discriminator, generator, latent_dim,\n                 discriminator_extra_steps=3, gp_weight=10.0):\n        super(WGAN, self).__init__()\n\n        self.discriminator = discriminator\n        self.generator = generator\n        self.latent_dim = latent_dim\n        self.d_steps = discriminator_extra_steps\n        self.gp_weight = gp_weight\n\n    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n        super(WGAN, self).compile()\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.d_loss_fn = d_loss_fn\n        self.g_loss_fn = g_loss_fn\n\n    # The Gradient Penalty method allows us to achieve faster convergence and higher stability while training\n    # It also enables us to achieve a better assignment of weights\n\n    def gradient_penalty(self, batch_size, real_images, fake_images):\n        # Get the interpolated image\n        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n        diff = fake_images - real_images\n        interpolated = real_images + alpha * diff\n\n        with tf.GradientTape() as gp_tape:\n            gp_tape.watch(interpolated)\n            pred = self.discriminator(interpolated, training=True)\n\n        grads = gp_tape.gradient(pred, [interpolated])[0]\n        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n        gp = tf.reduce_mean((norm - 1.0) ** 2)\n        return gp\n\n    def train_step(self, real_images):\n        if isinstance(real_images, tuple):\n            real_images = real_images[0]\n\n        batch_size = tf.shape(real_images)[0]\n\n        for i in range(self.d_steps):\n            # Get the latent vector\n            random_latent_vectors = tf.random.normal(\n                shape=(batch_size, self.latent_dim)\n            )\n            with tf.GradientTape() as tape:\n                # Generate fake images from the latent vector\n                fake_images = self.generator(random_latent_vectors, training=True)\n                # Get the logits for the fake images\n                fake_logits = self.discriminator(fake_images, training=True)\n                # Get the logits for the real images\n                real_logits = self.discriminator(real_images, training=True)\n\n                # Calculate the discriminator loss using the fake and real image logits\n                d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n                # Calculate the gradient penalty\n                gp = self.gradient_penalty(batch_size, real_images, fake_images)\n                # Add the gradient penalty to the original discriminator loss\n                d_loss = d_cost + gp * self.gp_weight\n\n            # Get the gradients w.r.t the discriminator loss\n            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n            # Update the weights of the discriminator using the discriminator optimizer\n            self.d_optimizer.apply_gradients(zip(d_gradient, self.discriminator.trainable_variables))\n\n        # Train the generator\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n        with tf.GradientTape() as tape:\n            # Generate fake images using the generator\n            generated_images = self.generator(random_latent_vectors, training=True)\n            # Get the discriminator logits for fake images\n            gen_img_logits = self.discriminator(generated_images, training=True)\n            # Calculate the generator loss\n            g_loss = self.g_loss_fn(gen_img_logits)\n\n        # Get the gradients w.r.t the generator loss\n        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n        # Update the weights of the generator using the generator optimizer\n        self.g_optimizer.apply_gradients(zip(gen_gradient, self.generator.trainable_variables))\n        return {\"d_loss\": d_loss, \"g_loss\": g_loss}","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:11:04.541301Z","iopub.execute_input":"2023-11-15T07:11:04.541964Z","iopub.status.idle":"2023-11-15T07:11:04.562874Z","shell.execute_reply.started":"2023-11-15T07:11:04.541924Z","shell.execute_reply":"2023-11-15T07:11:04.561734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using this custom callback we can save the generated images periodically\n\nclass GANMonitor(keras.callbacks.Callback):\n    def __init__(self, num_img=6, latent_dim=128):\n        self.num_img = num_img\n        self.latent_dim = latent_dim\n\n    def on_epoch_end(self, epoch, logs=None):\n        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n        generated_images = self.model.generator(random_latent_vectors)\n        generated_images = (generated_images * 127.5) + 127.5\n\n        for i in range(self.num_img):\n            img = generated_images[i].numpy()\n            img = keras.preprocessing.image.array_to_img(img)\n            img.save(\"generated_img_{i}_{epoch}.png\".format(i=i, epoch=epoch))","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:11:06.161918Z","iopub.execute_input":"2023-11-15T07:11:06.162334Z","iopub.status.idle":"2023-11-15T07:11:06.170177Z","shell.execute_reply.started":"2023-11-15T07:11:06.162304Z","shell.execute_reply":"2023-11-15T07:11:06.169153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Suggested hyperparameters in the research paper's algorithm\n\ngenerator_optimizer = keras.optimizers.Adam(\n\tlearning_rate=0.0002, beta_1=0.5, beta_2=0.9)\n\ndiscriminator_optimizer = keras.optimizers.Adam(\n    learning_rate=0.0002, beta_1=0.5, beta_2=0.9)\n\ndef discriminator_loss(real_img, fake_img):\n    real_loss = tf.reduce_mean(real_img)\n    fake_loss = tf.reduce_mean(fake_img)\n    return fake_loss - real_loss\n\ndef generator_loss(fake_img):\n    return -tf.reduce_mean(fake_img)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:11:10.310463Z","iopub.execute_input":"2023-11-15T07:11:10.310855Z","iopub.status.idle":"2023-11-15T07:11:10.322557Z","shell.execute_reply.started":"2023-11-15T07:11:10.310821Z","shell.execute_reply":"2023-11-15T07:11:10.321689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 20\n\n# Instantiate the custom defined Keras callback.\ncbk = GANMonitor(num_img=3, latent_dim=noise_dim)\n\n# Instantiate the WGAN model.\nwgan = WGAN(discriminator=d_model,\n\t\t\t      generator=g_model,\n            latent_dim=noise_dim,\n            discriminator_extra_steps=3,)\n\n# Compile the WGAN model.\nwgan.compile(d_optimizer=discriminator_optimizer,\n\t\t\t       g_optimizer=generator_optimizer,\n             g_loss_fn=generator_loss,\n             d_loss_fn=discriminator_loss,)\n\n# Start training the model.\nwgan.fit(images, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:12:50.356507Z","iopub.execute_input":"2023-11-15T07:12:50.356859Z","iopub.status.idle":"2023-11-15T07:14:01.212982Z","shell.execute_reply.started":"2023-11-15T07:12:50.356831Z","shell.execute_reply":"2023-11-15T07:14:01.212044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimage =  cv2.imread('/kaggle/working/generated_img_1_15.png')\nplt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:17:58.809396Z","iopub.execute_input":"2023-11-15T07:17:58.809832Z","iopub.status.idle":"2023-11-15T07:17:59.089597Z","shell.execute_reply.started":"2023-11-15T07:17:58.809801Z","shell.execute_reply":"2023-11-15T07:17:59.088689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}